# -*- coding: utf-8 -*-
"""
èŠå¤©å¯¹è¯æ¨¡å—

ä¼˜åŒ–åçš„èŠå¤©ç•Œé¢ï¼š
- ä½¿ç”¨ Gradio å­—å…¸æ ¼å¼ [{"role": "user", "content": "..."}, ...]
- ç”¨æˆ·æ¶ˆæ¯ç«‹å³æ˜¾ç¤º
- çœŸæ­£çš„æµå¼ä¼ è¾“
- æ”¯æŒå›è½¦å‘é€
"""
import gradio as gr
from typing import List, Dict, Optional


def create_chat_interface(web_app):
    """
    åˆ›å»ºèŠå¤©å¯¹è¯ç•Œé¢

    Args:
        web_app: BitwiseAIWeb å®ä¾‹

    Returns:
        èŠå¤©ç•Œé¢ç»„ä»¶
    """
    ai = web_app.ai

    def messages_to_context(messages: List[Dict[str, str]]) -> str:
        """
        å°†æ¶ˆæ¯åˆ—è¡¨è½¬æ¢ä¸ºä¸Šä¸‹æ–‡æ–‡æœ¬ï¼ˆç”¨äºæ„å»ºæŸ¥è¯¢ï¼‰
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨ [{"role": "user", "content": "..."}, ...]
            
        Returns:
            ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        context_text = ""
        for msg in messages:
            role = msg.get("role", "")
            content = msg.get("content", "")
            if role == "user" and content:
                context_text += f"ç”¨æˆ·: {content}\n"
            elif role == "assistant" and content:
                context_text += f"åŠ©æ‰‹: {content}\n"
        return context_text

    def chat_fn(message: str, history: List[Dict[str, str]], use_rag: bool, use_streaming: bool):
        """
        èŠå¤©å¤„ç†å‡½æ•°ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰
        
        ä½¿ç”¨ Gradio å­—å…¸æ ¼å¼ï¼š[{"role": "user", "content": "..."}, ...]

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            history: èŠå¤©å†å²ï¼ˆGradio å­—å…¸æ ¼å¼ï¼‰
            use_rag: æ˜¯å¦ä½¿ç”¨ RAG
            use_streaming: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º

        Yields:
            æ›´æ–°åçš„èŠå¤©å†å²
        """
        if not message or not message.strip():
            yield history or []
            return

        if not ai:
            history = history or []
            history.append({"role": "user", "content": message})
            history.append({"role": "assistant", "content": "âŒ BitwiseAI æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆé…ç½® API å¯†é’¥ã€‚"})
            yield history
            return

        history = history or []

        try:
            # 1. ç«‹å³æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
            history.append({"role": "user", "content": message})
            yield history  # ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯

            # 2. æ„å»ºä¸Šä¸‹æ–‡ï¼ˆä»å†å²æ¶ˆæ¯ä¸­æå–ï¼Œæ’é™¤åˆšæ·»åŠ çš„ç”¨æˆ·æ¶ˆæ¯ï¼‰
            context_messages = history[:-1]  # æ’é™¤åˆšæ·»åŠ çš„ç”¨æˆ·æ¶ˆæ¯
            
            # 3. æ„å»ºå½“å‰æŸ¥è¯¢ï¼ˆåŒ…å«å†å²ä¸Šä¸‹æ–‡ï¼‰
            if context_messages:
                context_text = messages_to_context(context_messages)
                current_query = context_text + f"ç”¨æˆ·: {message}"
            else:
                current_query = message

            # 4. è°ƒç”¨ AIï¼ˆæµå¼æˆ–éæµå¼ï¼‰ï¼Œä¼ é€’å†å²æ¶ˆæ¯
            if use_streaming:
                # çœŸæ­£çš„æµå¼è¾“å‡º
                response = ""
                # å…ˆæ·»åŠ ä¸€ä¸ªç©ºçš„ assistant æ¶ˆæ¯
                history.append({"role": "assistant", "content": ""})
                
                # ä¼ é€’å†å²æ¶ˆæ¯ï¼ˆæ’é™¤åˆšæ·»åŠ çš„ç”¨æˆ·æ¶ˆæ¯å’Œç©ºçš„ assistant æ¶ˆæ¯ï¼‰
                history_for_llm = context_messages
                
                for token in ai.chat_stream(message, use_rag=use_rag, use_tools=True, history=history_for_llm):
                    response += token
                    # æ›´æ–°æœ€åä¸€æ¡æ¶ˆæ¯ï¼ˆassistant å“åº”ï¼‰
                    history[-1] = {"role": "assistant", "content": response}
                    yield history
            else:
                # éæµå¼è¾“å‡º
                # ä¼ é€’å†å²æ¶ˆæ¯ï¼ˆæ’é™¤åˆšæ·»åŠ çš„ç”¨æˆ·æ¶ˆæ¯ï¼‰
                history_for_llm = context_messages
                response = ai.chat(message, use_rag=use_rag, use_tools=True, history=history_for_llm)
                history.append({"role": "assistant", "content": response})
                yield history

        except Exception as e:
            # é”™è¯¯å¤„ç†
            if history and history[-1].get("role") == "user":
                # å¦‚æœæœ€åä¸€æ¡æ˜¯ç”¨æˆ·æ¶ˆæ¯ï¼Œæ·»åŠ é”™è¯¯å“åº”
                history.append({"role": "assistant", "content": f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}"})
            else:
                # å¦‚æœå·²ç»æœ‰ assistant æ¶ˆæ¯ï¼Œæ›´æ–°å®ƒ
                history[-1] = {"role": "assistant", "content": f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}"}
            yield history

    def clear_chat():
        """æ¸…ç©ºèŠå¤©å†å²"""
        return []

    # åˆ›å»ºèŠå¤©ç•Œé¢
    with gr.Row() as interface:
        with gr.Column(scale=3):
            # èŠå¤©é…ç½®åŒºåŸŸ
            with gr.Row():
                use_rag_checkbox = gr.Checkbox(
                    value=True,
                    label="ä½¿ç”¨ RAG (çŸ¥è¯†åº“æ£€ç´¢)",
                    info="å¯ç”¨åä¼šä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹"
                )
                use_streaming_checkbox = gr.Checkbox(
                    value=True,
                    label="æµå¼è¾“å‡º",
                    info="å¯ç”¨åå®æ—¶æ˜¾ç¤º AI å›ç­”"
                )

            # èŠå¤©ç•Œé¢ï¼ˆä½¿ç”¨ Gradio å­—å…¸æ ¼å¼ï¼‰
            chatbot = gr.Chatbot(
                label="å¯¹è¯å†å²",
                height=500
            )

            with gr.Row():
                msg = gr.Textbox(
                    label="è¾“å…¥æ¶ˆæ¯",
                    placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...ï¼ˆæŒ‰ Enter å‘é€ï¼ŒShift+Enter æ¢è¡Œï¼‰",
                    scale=4,
                    lines=2,
                    max_lines=5
                )
                send_btn = gr.Button("å‘é€", scale=1, variant="primary")

            with gr.Row():
                clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯", variant="secondary")

            # ç¤ºä¾‹é—®é¢˜
            gr.Examples(
                examples=[
                    ["ä»€ä¹ˆæ˜¯ MUL æŒ‡ä»¤ï¼Ÿ"],
                    ["å¦‚ä½•éªŒè¯ SHIFT æŒ‡ä»¤ï¼Ÿ"],
                    ["PE å¯„å­˜å™¨çš„ func_sel å‚æ•°å«ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ"],
                    ["å¸®æˆ‘åˆ†æè¿™ä¸ªæ—¥å¿—æ–‡ä»¶ä¸­çš„é”™è¯¯"],
                ],
                inputs=msg,
                label="ç¤ºä¾‹é—®é¢˜"
            )

        with gr.Column(scale=1):
            # ç³»ç»Ÿä¿¡æ¯é¢æ¿
            gr.Markdown("### âš™ï¸ ç³»ç»ŸçŠ¶æ€")

            system_info = gr.Markdown(
                value=get_system_info(ai),
                label="ç³»ç»Ÿä¿¡æ¯"
            )

            refresh_info_btn = gr.Button("åˆ·æ–°çŠ¶æ€", size="sm")

            # å¿«æ·æ“ä½œ
            gr.Markdown("### âš¡ å¿«æ·æ“ä½œ")

            with gr.Column():
                set_prompt_btn = gr.Button("è®¾ç½®ç³»ç»Ÿæç¤ºè¯", size="sm")
                new_prompt = gr.Textbox(
                    label="æ–°æç¤ºè¯",
                    placeholder="è¾“å…¥æ–°çš„ç³»ç»Ÿæç¤ºè¯...",
                    lines=3
                )

            gr.Markdown("### ğŸ“– ä½¿ç”¨æç¤º")
            gr.Markdown("""
            - **RAG æ¨¡å¼**: ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³å†…å®¹åå›ç­”
            - **çº¯ LLM æ¨¡å¼**: ç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹å›ç­”
            - æ”¯æŒå¤šè½®å¯¹è¯ï¼Œä¸Šä¸‹æ–‡ä¼šè¢«ä¿ç•™
            - æŒ‰ **Enter** å‘é€æ¶ˆæ¯ï¼Œ**Shift+Enter** æ¢è¡Œ
            """)

    # äº‹ä»¶ç»‘å®š
    # å‘é€æŒ‰é’®ç‚¹å‡»
    send_btn.click(
        fn=chat_fn,
        inputs=[msg, chatbot, use_rag_checkbox, use_streaming_checkbox],
        outputs=chatbot
    ).then(
        fn=lambda: "",  # æ¸…ç©ºè¾“å…¥æ¡†
        outputs=msg
    )

    # å›è½¦å‘é€ï¼ˆEnter é”®ï¼‰
    msg.submit(
        fn=chat_fn,
        inputs=[msg, chatbot, use_rag_checkbox, use_streaming_checkbox],
        outputs=chatbot
    ).then(
        fn=lambda: "",  # æ¸…ç©ºè¾“å…¥æ¡†
        outputs=msg
    )

    # æ¸…ç©ºå¯¹è¯
    clear_btn.click(
        fn=clear_chat,
        outputs=chatbot
    )

    # åˆ·æ–°ç³»ç»Ÿä¿¡æ¯
    refresh_info_btn.click(
        fn=lambda: get_system_info(ai),
        outputs=system_info
    )

    # è®¾ç½®ç³»ç»Ÿæç¤ºè¯
    set_prompt_btn.click(
        fn=lambda p: set_system_prompt(p, ai),
        inputs=[new_prompt],
        outputs=system_info
    ).then(
        fn=lambda: "",
        outputs=new_prompt
    )

    return interface


def get_system_info(ai) -> str:
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    if not ai:
        return "âŒ BitwiseAI æœªåˆå§‹åŒ–"

    info = f"""
| é¡¹ç›® | çŠ¶æ€ |
|------|------|
| LLM æ¨¡å‹ | {ai.llm.model if hasattr(ai.llm, 'model') else 'Unknown'} |
| Embedding | {ai.embedding.model if hasattr(ai.embedding, 'model') else 'Unknown'} |
| å‘é‡åº“é›†åˆ | {ai.rag_engine.collection_name} |
| å¯ç”¨ Skills | {len(ai.skill_manager.list_available_skills())} ä¸ª |
| å·²åŠ è½½ Skills | {len(ai.skill_manager.list_loaded_skills())} ä¸ª |
| å·²æ³¨å†Œä»»åŠ¡ | {len(ai.tasks)} ä¸ª |
    """
    return info


def set_system_prompt(new_prompt: str, ai) -> str:
    """è®¾ç½®ç³»ç»Ÿæç¤ºè¯"""
    if not ai:
        return "âŒ BitwiseAI æœªåˆå§‹åŒ–"

    try:
        ai.set_system_prompt(new_prompt)
        return f"âœ… ç³»ç»Ÿæç¤ºè¯å·²æ›´æ–°\n\n{new_prompt[:100]}{'...' if len(new_prompt) > 100 else ''}"
    except Exception as e:
        return f"âŒ æ›´æ–°å¤±è´¥: {str(e)}"
