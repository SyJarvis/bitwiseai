# -*- coding: utf-8 -*-
"""
èŠå¤©å¯¹è¯æ¨¡å—
"""
import gradio as gr
from typing import List, Tuple


def create_chat_interface(web_app):
    """
    åˆ›å»ºèŠå¤©å¯¹è¯ç•Œé¢

    Args:
        web_app: BitwiseAIWeb å®ä¾‹

    Returns:
        èŠå¤©ç•Œé¢ç»„ä»¶
    """
    ai = web_app.ai

    def chat_fn(message: str, history: List, use_rag: bool, use_streaming: bool):
        """
        èŠå¤©å¤„ç†å‡½æ•°ï¼ˆæ”¯æŒæµå¼è¾“å‡ºï¼‰

        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            history: èŠå¤©å†å²
            use_rag: æ˜¯å¦ä½¿ç”¨ RAG
            use_streaming: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º

        Returns:
            èŠå¤©å†å² (æ·»åŠ æ–°å›å¤)
        """
        if not ai:
            history = history or []
            history.append({"role": "user", "content": message})
            history.append({"role": "assistant", "content": "BitwiseAI æœªåˆå§‹åŒ–ï¼Œè¯·å…ˆé…ç½® API å¯†é’¥ã€‚"})
            return history

        history = history or []

        try:
            # ä» history ä¸­æå–ä¸Šä¸‹æ–‡ï¼ˆGradio 6.x æ ¼å¼ï¼‰
            context = ""
            for h in history:
                if h["role"] == "user":
                    context += f"ç”¨æˆ·: {h['content']}\n"
                elif h["role"] == "assistant":
                    context += f"åŠ©æ‰‹: {h['content']}\n"

            # æ„å»ºå®Œæ•´æç¤ºè¯
            full_message = context + f"ç”¨æˆ·: {message}"

            # æ·»åŠ åˆ°å†å²ï¼ˆå…ˆæ·»åŠ ç”¨æˆ·æ¶ˆæ¯ï¼‰
            history.append({"role": "user", "content": message})

            # è°ƒç”¨ AIï¼ˆæµå¼æˆ–éæµå¼ï¼‰
            if use_streaming:
                # æµå¼è¾“å‡º
                response = ""
                history.append({"role": "assistant", "content": ""})
                
                for token in ai.chat_stream(full_message, use_rag=use_rag, use_tools=True):
                    response += token
                    history[-1]["content"] = response
                    yield history
            else:
                # éæµå¼è¾“å‡º
                response = ai.chat(full_message, use_rag=use_rag, use_tools=True)
                history.append({"role": "assistant", "content": response})
                yield history

        except Exception as e:
            history.append({"role": "user", "content": message})
            history.append({"role": "assistant", "content": f"âŒ å‘ç”Ÿé”™è¯¯: {str(e)}"})
            yield history

    def clear_chat():
        """æ¸…ç©ºèŠå¤©å†å²"""
        return []

    # åˆ›å»ºèŠå¤©ç•Œé¢
    with gr.Row() as interface:
        with gr.Column(scale=3):
            # èŠå¤©é…ç½®åŒºåŸŸ
            with gr.Row():
                use_rag_checkbox = gr.Checkbox(
                    value=True,
                    label="ä½¿ç”¨ RAG (çŸ¥è¯†åº“æ£€ç´¢)",
                    info="å¯ç”¨åä¼šä»çŸ¥è¯†åº“ä¸­æ£€ç´¢ç›¸å…³å†…å®¹"
                )
                use_streaming_checkbox = gr.Checkbox(
                    value=True,
                    label="æµå¼è¾“å‡º",
                    info="å¯ç”¨åå®æ—¶æ˜¾ç¤º AI å›ç­”"
                )

            # èŠå¤©ç•Œé¢
            chatbot = gr.Chatbot(
                label="å¯¹è¯å†å²"
            )

            with gr.Row():
                msg = gr.Textbox(
                    label="è¾“å…¥æ¶ˆæ¯",
                    placeholder="è¯·è¾“å…¥æ‚¨çš„é—®é¢˜...",
                    scale=4,
                    lines=2
                )
                send_btn = gr.Button("å‘é€", scale=1, variant="primary")

            with gr.Row():
                clear_btn = gr.Button("æ¸…ç©ºå¯¹è¯", variant="secondary")

            # ç¤ºä¾‹é—®é¢˜
            gr.Examples(
                examples=[
                    ["ä»€ä¹ˆæ˜¯ MUL æŒ‡ä»¤ï¼Ÿ"],
                    ["å¦‚ä½•éªŒè¯ SHIFT æŒ‡ä»¤ï¼Ÿ"],
                    ["PE å¯„å­˜å™¨çš„ func_sel å‚æ•°å«ä¹‰æ˜¯ä»€ä¹ˆï¼Ÿ"],
                    ["å¸®æˆ‘åˆ†æè¿™ä¸ªæ—¥å¿—æ–‡ä»¶ä¸­çš„é”™è¯¯"],
                ],
                inputs=msg,
                label="ç¤ºä¾‹é—®é¢˜"
            )

        with gr.Column(scale=1):
            # ç³»ç»Ÿä¿¡æ¯é¢æ¿
            gr.Markdown("### âš™ï¸ ç³»ç»ŸçŠ¶æ€")

            system_info = gr.Markdown(
                value=get_system_info(ai),
                label="ç³»ç»Ÿä¿¡æ¯"
            )

            refresh_info_btn = gr.Button("åˆ·æ–°çŠ¶æ€", size="sm")

            # å¿«æ·æ“ä½œ
            gr.Markdown("### âš¡ å¿«æ·æ“ä½œ")

            with gr.Column():
                set_prompt_btn = gr.Button("è®¾ç½®ç³»ç»Ÿæç¤ºè¯", size="sm")
                new_prompt = gr.Textbox(
                    label="æ–°æç¤ºè¯",
                    placeholder="è¾“å…¥æ–°çš„ç³»ç»Ÿæç¤ºè¯...",
                    lines=3
                )

            gr.Markdown("### ğŸ“– ä½¿ç”¨æç¤º")
            gr.Markdown("""
            - **RAG æ¨¡å¼**: ä»çŸ¥è¯†åº“æ£€ç´¢ç›¸å…³å†…å®¹åå›ç­”
            - **çº¯ LLM æ¨¡å¼**: ç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹å›ç­”
            - æ”¯æŒå¤šè½®å¯¹è¯ï¼Œä¸Šä¸‹æ–‡ä¼šè¢«ä¿ç•™
            """)

    # äº‹ä»¶ç»‘å®š
    send_btn.click(
        fn=chat_fn,
        inputs=[msg, chatbot, use_rag_checkbox, use_streaming_checkbox],
        outputs=chatbot
    ).then(
        fn=lambda: "",
        outputs=msg
    )

    msg.submit(
        fn=chat_fn,
        inputs=[msg, chatbot, use_rag_checkbox, use_streaming_checkbox],
        outputs=chatbot
    ).then(
        fn=lambda: "",
        outputs=msg
    )

    clear_btn.click(
        fn=clear_chat,
        outputs=chatbot
    )

    refresh_info_btn.click(
        fn=lambda: get_system_info(ai),
        outputs=system_info
    )

    set_prompt_btn.click(
        fn=lambda p: set_system_prompt(p, ai),
        inputs=[new_prompt],
        outputs=system_info
    ).then(
        fn=lambda: "",
        outputs=new_prompt
    )

    return interface


def get_system_info(ai) -> str:
    """è·å–ç³»ç»Ÿä¿¡æ¯"""
    if not ai:
        return "âŒ BitwiseAI æœªåˆå§‹åŒ–"

    info = f"""
| é¡¹ç›® | çŠ¶æ€ |
|------|------|
| LLM æ¨¡å‹ | {ai.llm.model if hasattr(ai.llm, 'model') else 'Unknown'} |
| Embedding | {ai.embedding.model if hasattr(ai.embedding, 'model') else 'Unknown'} |
| å‘é‡åº“é›†åˆ | {ai.rag_engine.collection_name} |
| å¯ç”¨ Skills | {len(ai.skill_manager.list_available_skills())} ä¸ª |
| å·²åŠ è½½ Skills | {len(ai.skill_manager.list_loaded_skills())} ä¸ª |
| å·²æ³¨å†Œä»»åŠ¡ | {len(ai.tasks)} ä¸ª |
    """
    return info


def set_system_prompt(new_prompt: str, ai) -> str:
    """è®¾ç½®ç³»ç»Ÿæç¤ºè¯"""
    if not ai:
        return "âŒ BitwiseAI æœªåˆå§‹åŒ–"

    try:
        ai.set_system_prompt(new_prompt)
        return f"âœ… ç³»ç»Ÿæç¤ºè¯å·²æ›´æ–°\n\n{new_prompt[:100]}{'...' if len(new_prompt) > 100 else ''}"
    except Exception as e:
        return f"âŒ æ›´æ–°å¤±è´¥: {str(e)}"
