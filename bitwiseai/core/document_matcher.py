# -*- coding: utf-8 -*-
"""
æ–‡æ¡£ååŒ¹é…å™¨

æ”¯æŒä»æŸ¥è¯¢ä¸­æå–æ–‡æ¡£åå…³é”®è¯ï¼Œå¹¶åŒ¹é…ç›¸å…³æ–‡æ¡£
"""
import os
import re
from typing import List, Dict, Optional, Set
from ..vector_database import MilvusDB


class DocumentNameMatcher:
    """
    æ–‡æ¡£ååŒ¹é…å™¨
    
    ä»å‘é‡æ•°æ®åº“åŠ è½½æ‰€æœ‰æ–‡æ¡£åï¼Œå»ºç«‹ç´¢å¼•ï¼Œæ”¯æŒæ¨¡ç³ŠåŒ¹é…
    """
    
    def __init__(
        self,
        vector_db: MilvusDB,
        match_threshold: float = 0.3
    ):
        """
        åˆå§‹åŒ–æ–‡æ¡£ååŒ¹é…å™¨
        
        Args:
            vector_db: å‘é‡æ•°æ®åº“å®ä¾‹
            match_threshold: åŒ¹é…é˜ˆå€¼ï¼ˆ0-1ï¼‰ï¼Œè¡¨ç¤ºè‡³å°‘éœ€è¦åŒ¹é…å¤šå°‘æ¯”ä¾‹çš„å…³é”®è¯
        """
        self.vector_db = vector_db
        self.match_threshold = match_threshold
        
        # æ–‡æ¡£åç´¢å¼•ï¼š{file_name: [source_file1, source_file2, ...]}
        self.file_name_index: Dict[str, List[str]] = {}
        
        # æ–‡æ¡£åå…³é”®è¯ç´¢å¼•ï¼š{keyword: Set[file_name]}
        self.keyword_index: Dict[str, Set[str]] = {}
        
        # æ‰€æœ‰æ–‡æ¡£ååˆ—è¡¨
        self.all_file_names: List[str] = []
        
        # æ˜¯å¦å·²åŠ è½½ç´¢å¼•
        self._index_loaded = False
    
    def load_index(self) -> bool:
        """
        ä»å‘é‡æ•°æ®åº“åŠ è½½æ‰€æœ‰æ–‡æ¡£åï¼Œå»ºç«‹ç´¢å¼•
        
        Returns:
            æ˜¯å¦æˆåŠŸåŠ è½½
        """
        if self._index_loaded:
            return True
        
        try:
            # ä»å‘é‡æ•°æ®åº“æŸ¥è¯¢æ‰€æœ‰æ–‡æ¡£çš„å”¯ä¸€æ–‡æ¡£å
            # ä½¿ç”¨Milvusçš„queryåŠŸèƒ½è·å–æ‰€æœ‰æ–‡æ¡£çš„source_fileå’Œfile_name
            query_result = self.vector_db.client.query(
                collection_name=self.vector_db.collection_name,
                filter="",  # æ— è¿‡æ»¤æ¡ä»¶
                limit=10000,  # é™åˆ¶æŸ¥è¯¢æ•°é‡
                output_fields=["source_file", "file_name", "file_name_keywords"]
            )
            
            if not query_result:
                self._index_loaded = True
                return True
            
            # å»ºç«‹ç´¢å¼•
            seen_files = set()
            for item in query_result:
                source_file = item.get("source_file", "")
                file_name = item.get("file_name", "")
                file_name_keywords = item.get("file_name_keywords", "")
                
                if not source_file or not file_name:
                    continue
                
                # é¿å…é‡å¤å¤„ç†åŒä¸€ä¸ªæ–‡ä»¶
                if source_file in seen_files:
                    continue
                seen_files.add(source_file)
                
                # æ·»åŠ åˆ°æ–‡æ¡£åç´¢å¼•
                if file_name not in self.file_name_index:
                    self.file_name_index[file_name] = []
                    self.all_file_names.append(file_name)
                
                if source_file not in self.file_name_index[file_name]:
                    self.file_name_index[file_name].append(source_file)
                
                # å»ºç«‹å…³é”®è¯ç´¢å¼•
                if file_name_keywords:
                    keywords = file_name_keywords.split()
                    for keyword in keywords:
                        if keyword not in self.keyword_index:
                            self.keyword_index[keyword] = set()
                        self.keyword_index[keyword].add(file_name)
            
            self._index_loaded = True
            print(f"âœ… æ–‡æ¡£åç´¢å¼•åŠ è½½å®Œæˆ: {len(self.all_file_names)} ä¸ªæ–‡æ¡£, {len(self.keyword_index)} ä¸ªå…³é”®è¯")
            return True
            
        except Exception as e:
            print(f"âš ï¸  åŠ è½½æ–‡æ¡£åç´¢å¼•å¤±è´¥: {e}")
            return False
    
    def extract_query_keywords(self, query: str) -> List[str]:
        """
        ä»æŸ¥è¯¢ä¸­æå–å…³é”®è¯
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
        
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        if not query:
            return []
        
        # å°è¯•ä½¿ç”¨jiebaåˆ†è¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        try:
            import jieba
            words = jieba.cut(query)
            # è¿‡æ»¤åœç”¨è¯å’Œå•å­—ç¬¦
            stop_words = {
                'çš„', 'æ˜¯', 'åœ¨', 'æœ‰', 'å’Œ', 'ä¸', 'æˆ–', 'ä½†', 'å¦‚æœ', 'å¦‚ä½•', 
                'ä»€ä¹ˆ', 'å“ªä¸ª', 'å“ªäº›', 'å—', 'å‘¢', 'å—', 'äº†', 'å•Š', 'å‘€',
                'çŸ¥é“', 'äº†è§£', 'è¯·é—®', 'èƒ½å¦', 'å¯ä»¥', 'åº”è¯¥', 'éœ€è¦'
            }
            keywords = [w for w in words if w not in stop_words and len(w) > 1]
            return keywords
        except ImportError:
            # å¦‚æœæ²¡æœ‰jiebaï¼Œä½¿ç”¨ç®€å•æ–¹æ³•
            # ç§»é™¤æ ‡ç‚¹ç¬¦å·
            text = re.sub(r'[^\w\s]', ' ', query)
            # åˆ†å‰²
            words = [w for w in text.split() if len(w) > 1]
            return words
    
    def match_documents(self, query: str) -> List[str]:
        """
        ä»æŸ¥è¯¢ä¸­åŒ¹é…æ–‡æ¡£åï¼Œè¿”å›åŒ¹é…çš„source_fileåˆ—è¡¨
        
        Args:
            query: ç”¨æˆ·æŸ¥è¯¢
        
        Returns:
            åŒ¹é…çš„source_fileåˆ—è¡¨ï¼ˆå¦‚æœæœªåŒ¹é…åˆ°ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼‰
        """
        # ç¡®ä¿ç´¢å¼•å·²åŠ è½½
        if not self._index_loaded:
            self.load_index()
        
        if not self.all_file_names:
            return []
        
        # æå–æŸ¥è¯¢å…³é”®è¯
        query_keywords = self.extract_query_keywords(query)
        if not query_keywords:
            return []
        
        # æ¨¡ç³ŠåŒ¹é…ï¼šæŸ¥æ‰¾åŒ…å«æŸ¥è¯¢å…³é”®è¯çš„æ–‡æ¡£å
        matched_file_names = set()
        
        query_lower = query.lower()
        
        # æ–¹æ³•0: ç›´æ¥æ£€æŸ¥æŸ¥è¯¢ä¸­çš„è¿ç»­å­ä¸²æ˜¯å¦åœ¨æ–‡æ¡£åä¸­ï¼ˆä¼˜å…ˆï¼‰
        # è¿™æ ·å¯ä»¥åŒ¹é… "PEæŒ‡ä»¤" è¿™æ ·çš„è¿ç»­ç»„åˆ
        for file_name in self.all_file_names:
            file_name_lower = file_name.lower()
            # ç§»é™¤æ ‡ç‚¹ç¬¦å·ï¼Œä¿ç•™ä¸­æ–‡ã€è‹±æ–‡ã€æ•°å­—
            query_clean = re.sub(r'[^\w\s]', '', query_lower)
            # å°è¯•åŒ¹é…2-10ä¸ªå­—ç¬¦çš„è¿ç»­å­ä¸²
            for i in range(len(query_clean)):
                found = False
                for length in range(2, min(11, len(query_clean) - i + 1)):
                    substring = query_clean[i:i+length].strip()
                    if len(substring) >= 2 and substring in file_name_lower:
                        matched_file_names.add(file_name)
                        found = True
                        break
                if found:
                    break
        
        # æ–¹æ³•1: ç›´æ¥åŒ¹é…æ–‡æ¡£åï¼ˆåŒ…å«æŸ¥è¯¢å…³é”®è¯ï¼‰
        for file_name in self.all_file_names:
            file_name_lower = file_name.lower()
            # æ£€æŸ¥æ–‡æ¡£åæ˜¯å¦åŒ…å«æŸ¥è¯¢ä¸­çš„å…³é”®è¯
            if any(keyword.lower() in file_name_lower for keyword in query_keywords):
                matched_file_names.add(file_name)
        
        # æ–¹æ³•2: é€šè¿‡å…³é”®è¯ç´¢å¼•åŒ¹é…
        for keyword in query_keywords:
            keyword_lower = keyword.lower()
            # åœ¨å…³é”®è¯ç´¢å¼•ä¸­æŸ¥æ‰¾
            for indexed_keyword, file_names in self.keyword_index.items():
                if keyword_lower in indexed_keyword.lower() or indexed_keyword.lower() in keyword_lower:
                    matched_file_names.update(file_names)
        
        # æ–¹æ³•3: è®¡ç®—åŒ¹é…åº¦ï¼ˆè‡³å°‘åŒ¹é…ä¸€å®šæ¯”ä¾‹çš„å…³é”®è¯ï¼‰
        if len(query_keywords) > 1:
            for file_name in self.all_file_names:
                file_name_keywords = self._get_file_name_keywords(file_name)
                if not file_name_keywords:
                    continue
                
                # è®¡ç®—åŒ¹é…çš„å…³é”®è¯æ•°é‡
                matched_count = sum(1 for qk in query_keywords 
                                  if any(qk.lower() in fk.lower() or fk.lower() in qk.lower() 
                                        for fk in file_name_keywords))
                
                # å¦‚æœåŒ¹é…çš„å…³é”®è¯æ¯”ä¾‹è¶…è¿‡é˜ˆå€¼ï¼Œåˆ™åŒ¹é…
                match_ratio = matched_count / len(query_keywords)
                if match_ratio >= self.match_threshold:
                    matched_file_names.add(file_name)
        
        # æ”¶é›†æ‰€æœ‰åŒ¹é…çš„source_file
        matched_source_files = []
        for file_name in matched_file_names:
            if file_name in self.file_name_index:
                matched_source_files.extend(self.file_name_index[file_name])
        
        # å»é‡
        matched_source_files = list(set(matched_source_files))
        
        if matched_source_files:
            print(f"ğŸ“„ åŒ¹é…åˆ° {len(matched_file_names)} ä¸ªæ–‡æ¡£: {', '.join([os.path.basename(f) for f in matched_source_files[:5]])}")
            if len(matched_source_files) > 5:
                print(f"   ... å…± {len(matched_source_files)} ä¸ªæ–‡ä»¶")
        
        return matched_source_files
    
    def _get_file_name_keywords(self, file_name: str) -> List[str]:
        """
        è·å–æ–‡æ¡£åçš„å…³é”®è¯åˆ—è¡¨
        
        Args:
            file_name: æ–‡æ¡£å
        
        Returns:
            å…³é”®è¯åˆ—è¡¨
        """
        # ä»ç´¢å¼•ä¸­æŸ¥æ‰¾
        for keyword, file_names in self.keyword_index.items():
            if file_name in file_names:
                # è¿”å›è¯¥æ–‡æ¡£åå¯¹åº”çš„æ‰€æœ‰å…³é”®è¯
                return [k for k, fns in self.keyword_index.items() if file_name in fns]
        
        # å¦‚æœç´¢å¼•ä¸­æ²¡æœ‰ï¼Œä½¿ç”¨ç®€å•åˆ†è¯
        return self.extract_query_keywords(file_name)
    
    def refresh_index(self) -> bool:
        """
        åˆ·æ–°ç´¢å¼•ï¼ˆé‡æ–°åŠ è½½ï¼‰
        
        Returns:
            æ˜¯å¦æˆåŠŸåˆ·æ–°
        """
        self._index_loaded = False
        self.file_name_index.clear()
        self.keyword_index.clear()
        self.all_file_names.clear()
        return self.load_index()


__all__ = ["DocumentNameMatcher"]

